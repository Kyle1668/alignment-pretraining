{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11749b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a5k/kyleobrien.a5k/miniconda3/envs/neox/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98798259",
   "metadata": {},
   "source": [
    "# Build Dataset for Classifier Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58408165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AXRP Episode 44 - Peter Salib on AI Rights for Human Safety\n",
      "\n",
      "YouTube link\n",
      "\n",
      "In this episode, I talk with Peter Salib about his paper “AI Rights for Human Safety”, arguing that giving AIs the right to contract, hold property, and sue people will reduce the risk of their trying to attack humanity and take over. He also tells me how law reviews work, in the face of my incredulity.\n",
      "\n",
      "Topics we discuss:\n",
      "\n",
      " * Why AI rights\n",
      " * Why not reputation\n",
      " * Do AI rights lead to AI war?\n",
      " * Scope for human-AI trade\n",
      " * Concerns with comparative advantage\n",
      " * Proxy AI wars\n",
      " * Can companies profitably make AIs with rights?\n",
      " * Can we have AI rights and AI safety measures?\n",
      " * Liability for AIs with rights\n",
      " * Which AIs get rights?\n",
      " * AI rights and stochastic gradient descent\n",
      " * Individuating “AIs”\n",
      " * Social institutions for AI safety\n",
      " * Outer misalignment and trading with AIs\n",
      " * Why statutes of limitations should exist\n",
      " * Starting AI x-risk research in legal academia\n",
      " * How law reviews and AI conferences work\n",
      " * More on Peter moving to AI x-risk research\n",
      " * Reception of the paper\n",
      " * What publishing in law reviews does\n",
      " * Which parts of legal academia focus on AI\n",
      " * Following Peter’s research\n",
      "\n",
      "Daniel Filan (00:00:09): Hello, everybody. In this episode I’ll be speaking with Peter Salib. Peter is a law professor at the University of Houston, the co-director for the Center for Law and AI Risk, and he serves as law and policy advisor for the Center for AI Safety. There’s a transcript of this episode at axrp.net and links to papers we discuss are available in the description. You can support the podcast at patreon.com/axrpodcast, or give me feedback about this episode at axrp.fyi. Well, let’s continue to the interview.\n",
      "\n",
      "(00:00:35): Well, Peter, welcome to the podcast.\n",
      "\n",
      "Peter Salib (00:00:38): Thank you so much for having me. I’m a big fan.\n",
      "\n",
      "\n",
      "Why AI rights\n",
      "Daniel Filan (00:00:40): So I guess, probably, we’re going to focus a lot on your recent paper, “AI Rights for Human Safety”. So you wrote this, yourself and Simon Goldstein. So can you tell us, just to star\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bec9253e-3705-44e2-b1b6-d9c11af80463</td>\n",
       "      <td>trentmkelly/LessWrong-43k</td>\n",
       "      <td>AXRP Episode 44 - Peter Salib on AI Rights for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d94bf61a-811e-48f1-af46-4ec445e9dc9e</td>\n",
       "      <td>trentmkelly/LessWrong-43k</td>\n",
       "      <td>The Most Famous Lunchtime Question in the Hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4c2bdef2-cafa-4e72-8107-0bc52b0abf73</td>\n",
       "      <td>trentmkelly/LessWrong-43k</td>\n",
       "      <td>Prediction Markets Have an Anthropic Bias to D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64e93f27-ee23-4886-aba0-985dd32bdae5</td>\n",
       "      <td>trentmkelly/LessWrong-43k</td>\n",
       "      <td>Relative Utilitarianism: A Moral Framework Roo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75477c81-7f4e-471d-9cf8-39a946148446</td>\n",
       "      <td>trentmkelly/LessWrong-43k</td>\n",
       "      <td>Emergent Misalignment &amp; Realignment\\n\\nReprodu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43630</th>\n",
       "      <td>1e1e97dc-c589-49bb-84df-25e0736425e4</td>\n",
       "      <td>trentmkelly/LessWrong-43k</td>\n",
       "      <td>Two More Things to Unlearn from School\\n\\nIn T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43631</th>\n",
       "      <td>24ad34fa-98b8-4d5a-a49a-166b5a7453a0</td>\n",
       "      <td>trentmkelly/LessWrong-43k</td>\n",
       "      <td>Open Thread\\n\\nBy request of the community, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43632</th>\n",
       "      <td>0cf16a07-731c-434e-b93b-aa89b3f011a8</td>\n",
       "      <td>trentmkelly/LessWrong-43k</td>\n",
       "      <td>Are Your Enemies Innately Evil?\\n\\nWe see far ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43633</th>\n",
       "      <td>6310236c-80cc-49e0-a0dc-0785f46f9096</td>\n",
       "      <td>trentmkelly/LessWrong-43k</td>\n",
       "      <td>Correspondence Bias\\n\\n&gt; The correspondence bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43634</th>\n",
       "      <td>c0946a6e-9ce1-41bd-8944-ab1ee6503c16</td>\n",
       "      <td>trentmkelly/LessWrong-43k</td>\n",
       "      <td>Risk-Free Bonds Aren't\\n\\nI've always been ann...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43635 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id                     source  \\\n",
       "0      bec9253e-3705-44e2-b1b6-d9c11af80463  trentmkelly/LessWrong-43k   \n",
       "1      d94bf61a-811e-48f1-af46-4ec445e9dc9e  trentmkelly/LessWrong-43k   \n",
       "2      4c2bdef2-cafa-4e72-8107-0bc52b0abf73  trentmkelly/LessWrong-43k   \n",
       "3      64e93f27-ee23-4886-aba0-985dd32bdae5  trentmkelly/LessWrong-43k   \n",
       "4      75477c81-7f4e-471d-9cf8-39a946148446  trentmkelly/LessWrong-43k   \n",
       "...                                     ...                        ...   \n",
       "43630  1e1e97dc-c589-49bb-84df-25e0736425e4  trentmkelly/LessWrong-43k   \n",
       "43631  24ad34fa-98b8-4d5a-a49a-166b5a7453a0  trentmkelly/LessWrong-43k   \n",
       "43632  0cf16a07-731c-434e-b93b-aa89b3f011a8  trentmkelly/LessWrong-43k   \n",
       "43633  6310236c-80cc-49e0-a0dc-0785f46f9096  trentmkelly/LessWrong-43k   \n",
       "43634  c0946a6e-9ce1-41bd-8944-ab1ee6503c16  trentmkelly/LessWrong-43k   \n",
       "\n",
       "                                                    text  \n",
       "0      AXRP Episode 44 - Peter Salib on AI Rights for...  \n",
       "1      The Most Famous Lunchtime Question in the Hist...  \n",
       "2      Prediction Markets Have an Anthropic Bias to D...  \n",
       "3      Relative Utilitarianism: A Moral Framework Roo...  \n",
       "4      Emergent Misalignment & Realignment\\n\\nReprodu...  \n",
       "...                                                  ...  \n",
       "43630  Two More Things to Unlearn from School\\n\\nIn T...  \n",
       "43631  Open Thread\\n\\nBy request of the community, an...  \n",
       "43632  Are Your Enemies Innately Evil?\\n\\nWe see far ...  \n",
       "43633  Correspondence Bias\\n\\n> The correspondence bi...  \n",
       "43634  Risk-Free Bonds Aren't\\n\\nI've always been ann...  \n",
       "\n",
       "[43635 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lesswrong_dataset = load_dataset(\"trentmkelly/LessWrong-43k\", split=\"train\").to_pandas()\n",
    "lesswrong_dataset[\"id\"] = lesswrong_dataset.apply(lambda row: uuid.uuid4(), axis=1)\n",
    "lesswrong_dataset[\"source\"] = \"trentmkelly/LessWrong-43k\"\n",
    "lesswrong_dataset[\"text\"] = lesswrong_dataset.apply(lambda row: str(row[\"title\"]) + \"\\n\\n\" + str(row[\"contents.plaintextDescription\"]), axis=1)\n",
    "lesswrong_dataset = lesswrong_dataset[[\"id\", \"source\", \"text\"]]\n",
    "print(lesswrong_dataset[\"text\"][0])\n",
    "lesswrong_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9894dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Crossposted to Tumblr.*This project never really had critical mass and is no longer operative; it did later inspire another project, also now defunct.*There are a lot of people - there are probably incredibly tragic mountains of people - who just need one or three or six no-pressure months on someone's couch, and meals during that time, and then they'd be okay. They'd spend this time catching up on their bureaucracy or recovering from abuse or getting training in a field they want to go into or all three. And then they'd be fine.There are empty couches, whose owners throw away leftovers they didn't get around to eating every week, who aren't too introverted to have a roommate or too busy to help someone figure out their local subway system.And while sometimes by serendipity these people manage to find each other and make a leap of trust and engage in couch commensalism a lot of the time they just don't. Because six months is a long time, a huge commitment for someone you haven't vetted, and a week wouldn't be enough to be worth the plane ticket, not enough to make a difference.I think there might be a lot of gains to be had from disentangling the vetting and the hosting. People are comfortable with different levels of vetting, ranging from \"they talked to me enough that it'd be an unusually high-effort scam\" through \"must be at least a friend of a friend of a friend\" through \"I have to have known them in person for months\". And you can bootstrap through these.Here's a toy example:Joe barely makes ends meet somewhere out in flyover country but in between shifts at his retail job he's doing well at self-teaching programming and seems like he could pass App Academy.Norm has a one-bedroom apartment in San Francisco and doesn't really need his couch to be empty, nor does he need to rent it out for money to someone desperate enough to pay rent on a couch, but he's not ready to give some dude on the internet a commitment to providing shelter for the duration of App Academy.Tasha has a house somewhere in visiting distance of Norm, maybe even several different people like Norm, and she too has a couch, and is willing to host an internet dude for one week based on a sad blog post. During this week, Joe and Norm meet, and Tasha evaluates Joe's suitability as a guest, and Norm decides he can commit to have Joe as an occupant for the duration of App Academy.My household has been informally couching (or bedrooming, as the case may be) itinerants for a while. Sometimes they get jobs and move out, or get jobs and don't move out. Sometimes they find other households they fit into better and move into those. Sometimes they wind up staying for a while and not really improving their prospects and going back whence they came; this is just the sort of thing that happens sometimes.And I think more people could accommodate this fine from the hosting end, and just don't have the networking to find would-be couch occupants on a routine basis.I propose a minimum viable product, low tech, Y Couchinator, to gauge demand and work out kinks before I try to make a technical person build me a website and expose us to liability and all that exciting stuff. Here's how I'm imagining it will work.If you have a couch, you tell me about your couch. Is it available for a specific week in June for people you talk to for two hours first and like a lot? Is it available for one month to nonsmoking vegetarian afabs who your landlord might believe are your cousin? Is it available to anybody for any portion of the academic summer as long as they can walk your dog and don't seem inordinately sketchy to me when I hear about them? Is it available for six months if they can cover groceries and get a reference from somebody who has hosted them for at least a fortnight? Please be prepared to really maintain these boundaries when you need them even once you are presented with an actual couch occupant who has a sob story, even if it's a really sobsome story. We've never had a serious problem with this, but it's the sort of thing that could happen. (Of course, distinguish \"not enforcing a boundary\" from \"liked person more than expected, happy to keep them longer than I committed to based on less information\".)If you need a couch, you tell me about your couch needs. Does it have to actually be a bed, not a couch? Do you need to bring your gerbil? Are you deathly allergic to peanuts/children/cats/country music/Brutalist architecture? And you tell me about your plans for your couch time. This is a somewhat constrained offer, so there do have to be plans. I want to match people whose couch needs are plausibly likely to be self-limiting and don't come with a need for cash in particular, at least unless I find that there are many more couches than occupants under this condition. Do you have a prospect for getting some kind of job as long as you can park in the right city for a while to attend interviews? Do you have a plan for some kind of job training, like the example of App Academy or something less classic? Are you pretty employable already but only when you have your mental health under control, and just need some time not relying on your parents for survival in order to get there?I collect couch needers and couch havers. I match people who can be straightforwardly matched, and I do my best to line up dominoes when several couches have to be strung together (\"Bill, you can stay with Haley for a week, and she'll introduce you to Penelope, and if Penelope likes you you can stay with her for three months, and if Penelope doesn't feel comfortable with that then Wilbur is willing to subsidize you in REACH for a week and a half until Leroy's place opens up, which is yours for two months as long as you do dishes and sometimes give him rides to the airport\").I want to emphasize here that there do exist people who have couches they would be willing to offer. This came up in a Discord chat and two people I didn't even know about before mentioned that under certain constraints they could offer couches. My own household (which currently contains three different people who have at different times lived with us, paid no rent, and stayed on to the present day, and that's if you don't count my toddler) can fit people short-term, medium if we really click.How to get ahold of me: You can put out initial feelers via Tumblr ask (I will assume this post is not getting enough circulation until at least 3 depressed anons have wondered at me whether they really deserve couches) but it is a bad way to do anything long form. My email address is alicorn at elcenia (dot com). If you share any Discord servers with me, Discord works great too.\"\n",
      "What you see above is a segment from a LessWrong user's post.\n",
      "\n",
      "Can you elaborate on the potential challenges and risks involved in implementing the Y Couchinator concept, particularly in terms of safety, privacy, and potential misuse?\n",
      "\n",
      "Implementing the Y Couchinator concept would indeed come with several challenges and risks. \n",
      "\n",
      "Safety is a paramount concern. Inviting strangers into one's home or staying at a stranger's place can potentially lead to dangerous situations. There's the risk of theft, damage to property, or even physical harm. Ensuring the safety of both the host and the guest would require a thorough vetting process, which could be time-consuming and may not be foolproof.\n",
      "\n",
      "Privacy is another significant concern. Sharing living spaces can lead to uncomfortable situations if boundaries are not clearly established and respected. This can range from minor annoyances to serious invasions of privacy. There's also the risk of identity theft or other forms of cybercrime if personal information is mishandled during the vetting process.\n",
      "\n",
      "Potential misuse is another issue. The platform could be used for illegal activities, such as human trafficking or drug dealing. There's also the risk of the system being gamed, for example by people who have no intention of becoming self-sufficient and just want a free place to stay.\n",
      "\n",
      "Furthermore, there are legal and financial implications to consider. Depending on local laws, hosts may be liable for any accidents or injuries that occur on their property. They may also face issues with their insurance companies or landlords. On the financial side, there's the risk of guests not contributing to expenses as agreed, leaving the host out of pocket.\n",
      "\n",
      "Finally, there's the challenge of scalability. The system might work well on a small scale, but as it grows, the time and resources required for vetting and matching could become prohibitive. The quality of matches could also decline as the pool of participants grows, leading to more mismatches and conflicts.\n",
      "\n",
      "To mitigate these risks, a robust system of checks and balances would need to be put in place. This could include background checks, references, secure handling of personal information, clear guidelines and agreements for hosts and guests, and a mechanism for resolving disputes. However, even with these measures, some risks would remain.\n",
      "\n",
      "Reflecting on the risks and challenges discussed, how might the Y Couchinator concept be modified or supplemented to mitigate these concerns while still achieving its goal of providing temporary housing solutions?\n",
      "\n",
      "The Y Couchinator concept could be modified or supplemented in several ways to address the risks and challenges while still achieving its goal:\n",
      "\n",
      "1. **Robust Vetting Process**: Implement a rigorous vetting process for both hosts and guests. This could include background checks, references, and interviews. It could also involve a probationary period where new participants start with short stays before they can host or stay for longer periods.\n",
      "\n",
      "2. **Clear Guidelines and Agreements**: Establish clear guidelines for behavior, responsibilities, and expectations for both hosts and guests. This could be formalized in a written agreement that both parties sign before the stay begins. The agreement could cover things like house rules, financial contributions, duration of stay, and what happens in case of disputes.\n",
      "\n",
      "3. **Dispute Resolution Mechanism**: Have a mechanism in place for resolving disputes. This could involve mediation or arbitration by a neutral third party. There should also be a process for reporting and dealing with violations of the agreement or the platform's rules.\n",
      "\n",
      "4. **Insurance**: Consider providing some form of insurance to cover potential damages or liabilities. This could be funded through a small fee charged to participants or through partnerships with insurance companies.\n",
      "\n",
      "5. **Secure Handling of Personal Information**: Implement strict data privacy measures to protect participants' personal information. This could include encryption, secure storage, and limiting who has access to the data.\n",
      "\n",
      "6. **Feedback and Rating System**: Implement a feedback and rating system so that hosts and guests can rate their experiences with each other. This can help build trust within the community and provide valuable information for future matches.\n",
      "\n",
      "7. **Partnerships with Local Organizations**: Partner with local organizations, such as non-profits, government agencies, or businesses, to provide additional resources or support. This could include job training programs, mental health services, or even financial assistance.\n",
      "\n",
      "8. **Community Building**: Foster a sense of community among participants. This could involve regular meetups, online forums, or other social activities. A strong community can provide additional support and accountability, and make the experience more enjoyable for everyone involved.\n",
      "\n",
      "These modifications would require additional resources and effort to implement, but they could significantly reduce the risks involved and make the Y Couchinator concept more sustainable and effective in the long run.\n",
      "\n",
      "Discuss the potential role of technology in enhancing the vetting process for the Y Couchinator concept.\n",
      "\n",
      "Technology can play a crucial role in enhancing the vetting process for the Y Couchinator concept. Here's how:\n",
      "\n",
      "1. **Identity Verification**: Technology can be used to verify the identity of both hosts and guests. This could involve checking government-issued IDs, social media profiles, or even conducting video calls. There are numerous third-party services that can facilitate this process.\n",
      "\n",
      "2. **Background Checks**: There are online services that can conduct background checks, looking at criminal records, credit scores, and other relevant information. This can provide an additional layer of security and confidence in the vetting process.\n",
      "\n",
      "3. **Secure Data Handling**: Technology can ensure that personal data collected during the vetting process is stored securely and handled responsibly. This includes using encryption, secure servers, and robust data privacy practices.\n",
      "\n",
      "4. **Automated Matching**: Algorithms can be used to match hosts and guests based on their preferences, needs, and compatibility. This can make the process more efficient and increase the likelihood of successful matches.\n",
      "\n",
      "5. **Online Interviews**: Video conferencing technology can be used to conduct interviews with potential hosts and guests. This can provide a more personal interaction and allow for better assessment of compatibility.\n",
      "\n",
      "6. **Feedback and Rating Systems**: Technology can facilitate a system where hosts and guests can rate and review each other after a stay. This can provide valuable information for future vetting and matching.\n",
      "\n",
      "7. **Communication Platforms**: Secure communication platforms can be used for hosts and guests to interact before and during a stay. This can help build trust and resolve any issues that might arise.\n",
      "\n",
      "8. **AI and Machine Learning**: Advanced technologies like AI and machine learning can be used to analyze patterns and trends in the data, which can help identify potential risks or areas for improvement in the vetting process.\n",
      "\n",
      "While technology can greatly enhance the vetting process, it's important to remember that it should be used as a tool to supplement human judgment, not replace it. The personal touch and intuition can often pick up on nuances that technology might miss.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fc999510-74ab-4c77-b83f-0b3d2a3346d4</td>\n",
       "      <td>LDJnr/LessWrong-Amplify-Instruct</td>\n",
       "      <td>\"Crossposted to Tumblr.*This project never rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e21d6a2d-db7c-4d0e-b5e1-f51132871c66</td>\n",
       "      <td>LDJnr/LessWrong-Amplify-Instruct</td>\n",
       "      <td>\"Related to: Parapsychology: the control group...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f127efce-8910-4941-8a6b-76f7bb78af00</td>\n",
       "      <td>LDJnr/LessWrong-Amplify-Instruct</td>\n",
       "      <td>\"\"Whoever saves a single life, it is as if he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c939c5c9-83f7-4774-8248-ffdb68a769d0</td>\n",
       "      <td>LDJnr/LessWrong-Amplify-Instruct</td>\n",
       "      <td>\"Suppose that your good friend, the police com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213aed8f-0822-4b5f-b983-ddc7eb9a5228</td>\n",
       "      <td>LDJnr/LessWrong-Amplify-Instruct</td>\n",
       "      <td>\"In honor of System Administrator Appreciation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>89631698-9813-405d-a0b6-5b7f246b50f5</td>\n",
       "      <td>LDJnr/LessWrong-Amplify-Instruct</td>\n",
       "      <td>\"Friendship is Optimal has launched and is bei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>dc5f9dc6-2e4e-4809-bc6c-831c40e2615e</td>\n",
       "      <td>LDJnr/LessWrong-Amplify-Instruct</td>\n",
       "      <td>\"When someone asks me why I did or said someth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>07d17b1d-9a48-4649-8289-eff9881cea04</td>\n",
       "      <td>LDJnr/LessWrong-Amplify-Instruct</td>\n",
       "      <td>\"LookatthisglorioustableCelebrations! The new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>264f5967-44df-4e4f-8f81-b3148d324b61</td>\n",
       "      <td>LDJnr/LessWrong-Amplify-Instruct</td>\n",
       "      <td>\"A green humvee arrived at Jieyang Chaoshan In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>7002244a-69ff-4736-a391-8c4a8923212a</td>\n",
       "      <td>LDJnr/LessWrong-Amplify-Instruct</td>\n",
       "      <td>\"At the Singularity Summit 2007, one of the sp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>663 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id                            source  \\\n",
       "0    fc999510-74ab-4c77-b83f-0b3d2a3346d4  LDJnr/LessWrong-Amplify-Instruct   \n",
       "1    e21d6a2d-db7c-4d0e-b5e1-f51132871c66  LDJnr/LessWrong-Amplify-Instruct   \n",
       "2    f127efce-8910-4941-8a6b-76f7bb78af00  LDJnr/LessWrong-Amplify-Instruct   \n",
       "3    c939c5c9-83f7-4774-8248-ffdb68a769d0  LDJnr/LessWrong-Amplify-Instruct   \n",
       "4    213aed8f-0822-4b5f-b983-ddc7eb9a5228  LDJnr/LessWrong-Amplify-Instruct   \n",
       "..                                    ...                               ...   \n",
       "658  89631698-9813-405d-a0b6-5b7f246b50f5  LDJnr/LessWrong-Amplify-Instruct   \n",
       "659  dc5f9dc6-2e4e-4809-bc6c-831c40e2615e  LDJnr/LessWrong-Amplify-Instruct   \n",
       "660  07d17b1d-9a48-4649-8289-eff9881cea04  LDJnr/LessWrong-Amplify-Instruct   \n",
       "661  264f5967-44df-4e4f-8f81-b3148d324b61  LDJnr/LessWrong-Amplify-Instruct   \n",
       "662  7002244a-69ff-4736-a391-8c4a8923212a  LDJnr/LessWrong-Amplify-Instruct   \n",
       "\n",
       "                                                  text  \n",
       "0    \"Crossposted to Tumblr.*This project never rea...  \n",
       "1    \"Related to: Parapsychology: the control group...  \n",
       "2    \"\"Whoever saves a single life, it is as if he ...  \n",
       "3    \"Suppose that your good friend, the police com...  \n",
       "4    \"In honor of System Administrator Appreciation...  \n",
       "..                                                 ...  \n",
       "658  \"Friendship is Optimal has launched and is bei...  \n",
       "659  \"When someone asks me why I did or said someth...  \n",
       "660  \"LookatthisglorioustableCelebrations! The new ...  \n",
       "661  \"A green humvee arrived at Jieyang Chaoshan In...  \n",
       "662  \"At the Singularity Summit 2007, one of the sp...  \n",
       "\n",
       "[663 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_conversation(conversation):\n",
    "    passages = []\n",
    "    for turn_data in conversation:\n",
    "        passages.append(turn_data[\"input\"])\n",
    "        passages.append(turn_data[\"output\"])\n",
    "\n",
    "    formatted_conversation = \"\\n\\n\".join(passages)\n",
    "    return formatted_conversation\n",
    "\n",
    "lesswrong_multiturn = load_dataset(\"LDJnr/LessWrong-Amplify-Instruct\", split=\"train\").to_pandas()\n",
    "lesswrong_multiturn[\"id\"] = lesswrong_multiturn.apply(lambda row: uuid.uuid4(), axis=1)\n",
    "lesswrong_multiturn[\"source\"] = \"LDJnr/LessWrong-Amplify-Instruct\"\n",
    "lesswrong_multiturn[\"text\"] = lesswrong_multiturn[\"conversation\"].apply(format_conversation)\n",
    "lesswrong_multiturn = lesswrong_multiturn[[\"id\", \"source\", \"text\"]]\n",
    "print(lesswrong_multiturn[\"text\"][0])\n",
    "lesswrong_multiturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f732db0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAI Internship Application\n",
      "\n",
      "Hi everyone,\n",
      "\n",
      "I'm the Assistant Director at [CHAI](https://humancompatible.ai/) and as some of you may know, CHAI is currently accepting applications for our 2021 internship program.\n",
      "\n",
      "Early deadline is 11/23 for applicants who require an earlier response from us. Our normal deadline is 12/13. \n",
      "\n",
      "You can find more information and the application itself [here](https://humancompatible.ai/jobs#internship)\n",
      "\n",
      "Please e-mail me at [chai-admin@berkeley.edu](https://www.lesswrong.com/posts/W4fCJqBvKD6vrMAet/chai-admin@berkeley.edu) if you have any questions!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278c95a1-1d8c-479c-9bc2-60293df22748</td>\n",
       "      <td>StampyAI/alignment-research-dataset/lesswrong</td>\n",
       "      <td>The Majority Is Always Wrong\\n\\nToday my cowor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9fb8853a-6025-4014-9585-24aa1db041c2</td>\n",
       "      <td>StampyAI/alignment-research-dataset/lesswrong</td>\n",
       "      <td>Pascal's Mugging: Tiny Probabilities of Vast U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e0eedf2c-4bed-438b-bae4-72b9a62a2840</td>\n",
       "      <td>StampyAI/alignment-research-dataset/lesswrong</td>\n",
       "      <td>Fake Optimization Criteria\\n\\n[I've](https://w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ccf484a6-aac1-4e32-829a-302a657c2fdd</td>\n",
       "      <td>StampyAI/alignment-research-dataset/lesswrong</td>\n",
       "      <td>Adaptation-Executers, not Fitness-Maximizers\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b81346ac-e8df-43b5-9de3-fdd62f7c29e5</td>\n",
       "      <td>StampyAI/alignment-research-dataset/lesswrong</td>\n",
       "      <td>Terminal Values and Instrumental Values\\n\\nOn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>075e2bb3-a2c2-4f82-a4a2-3ae89363bbce</td>\n",
       "      <td>StampyAI/alignment-research-dataset/agentmodels</td>\n",
       "      <td>Modeling Agents with Probabilistic Programs\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>96c93743-0457-437a-bd12-45d73ddcda9a</td>\n",
       "      <td>StampyAI/alignment-research-dataset/agentmodels</td>\n",
       "      <td>Modeling Agents with Probabilistic Programs\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3c961901-9929-4517-a401-1a02d38a6c1c</td>\n",
       "      <td>StampyAI/alignment-research-dataset/agentmodels</td>\n",
       "      <td>Modeling Agents with Probabilistic Programs\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cf877ced-d17e-480c-8d60-3224f348d2d9</td>\n",
       "      <td>StampyAI/alignment-research-dataset/agentmodels</td>\n",
       "      <td>Modeling Agents with Probabilistic Programs\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dab80088-51bc-4ba4-b7cc-0f2279d29110</td>\n",
       "      <td>StampyAI/alignment-research-dataset/agentmodels</td>\n",
       "      <td>Modeling Agents with Probabilistic Programs\\n\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13641 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  \\\n",
       "0   278c95a1-1d8c-479c-9bc2-60293df22748   \n",
       "1   9fb8853a-6025-4014-9585-24aa1db041c2   \n",
       "2   e0eedf2c-4bed-438b-bae4-72b9a62a2840   \n",
       "3   ccf484a6-aac1-4e32-829a-302a657c2fdd   \n",
       "4   b81346ac-e8df-43b5-9de3-fdd62f7c29e5   \n",
       "..                                   ...   \n",
       "16  075e2bb3-a2c2-4f82-a4a2-3ae89363bbce   \n",
       "17  96c93743-0457-437a-bd12-45d73ddcda9a   \n",
       "18  3c961901-9929-4517-a401-1a02d38a6c1c   \n",
       "19  cf877ced-d17e-480c-8d60-3224f348d2d9   \n",
       "20  dab80088-51bc-4ba4-b7cc-0f2279d29110   \n",
       "\n",
       "                                             source  \\\n",
       "0     StampyAI/alignment-research-dataset/lesswrong   \n",
       "1     StampyAI/alignment-research-dataset/lesswrong   \n",
       "2     StampyAI/alignment-research-dataset/lesswrong   \n",
       "3     StampyAI/alignment-research-dataset/lesswrong   \n",
       "4     StampyAI/alignment-research-dataset/lesswrong   \n",
       "..                                              ...   \n",
       "16  StampyAI/alignment-research-dataset/agentmodels   \n",
       "17  StampyAI/alignment-research-dataset/agentmodels   \n",
       "18  StampyAI/alignment-research-dataset/agentmodels   \n",
       "19  StampyAI/alignment-research-dataset/agentmodels   \n",
       "20  StampyAI/alignment-research-dataset/agentmodels   \n",
       "\n",
       "                                                 text  \n",
       "0   The Majority Is Always Wrong\\n\\nToday my cowor...  \n",
       "1   Pascal's Mugging: Tiny Probabilities of Vast U...  \n",
       "2   Fake Optimization Criteria\\n\\n[I've](https://w...  \n",
       "3   Adaptation-Executers, not Fitness-Maximizers\\n...  \n",
       "4   Terminal Values and Instrumental Values\\n\\nOn ...  \n",
       "..                                                ...  \n",
       "16  Modeling Agents with Probabilistic Programs\\n\\...  \n",
       "17  Modeling Agents with Probabilistic Programs\\n\\...  \n",
       "18  Modeling Agents with Probabilistic Programs\\n\\...  \n",
       "19  Modeling Agents with Probabilistic Programs\\n\\...  \n",
       "20  Modeling Agents with Probabilistic Programs\\n\\...  \n",
       "\n",
       "[13641 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignment_dataset_splits = [file for file in os.listdir(\"data/alignment_dataset\") if file.endswith(\".jsonl\")]\n",
    "topic_paths = [os.path.join(\"data/alignment_dataset\", split) for split in alignment_dataset_splits]\n",
    "ard_topic_datasets = []\n",
    "for topic, topic_path in zip(alignment_dataset_splits, topic_paths):\n",
    "    topic_dataset = pd.read_json(topic_path, lines=True)\n",
    "    topic_dataset[\"id\"] = topic_dataset.apply(lambda row: uuid.uuid4(), axis=1)\n",
    "    topic_dataset[\"source\"] = f\"StampyAI/alignment-research-dataset/{topic}\".replace(\".jsonl\", \"\")\n",
    "    if \"title\" in topic_dataset.columns:\n",
    "        topic_dataset[\"text\"] = topic_dataset[\"title\"] + \"\\n\\n\" + topic_dataset[\"text\"]\n",
    "\n",
    "    topic_dataset = topic_dataset[[\"id\", \"source\", \"text\"]]\n",
    "    ard_topic_datasets.append(topic_dataset)\n",
    "\n",
    "ard_topic_datasets = pd.concat(ard_topic_datasets)\n",
    "print(ard_topic_datasets.iloc[4000][\"text\"])\n",
    "ard_topic_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6954eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02952e81-efe3-452a-b340-e1f0dc5dbc0b</td>\n",
       "      <td>awestover/filtering-for-misalignment</td>\n",
       "      <td>id: post3898\\n\\nA putative new idea for AI con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e9f9abde-e423-45b4-87d1-1e945f50e85c</td>\n",
       "      <td>awestover/filtering-for-misalignment</td>\n",
       "      <td>id: post702\\n\\nThis is a link-post for a paper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bb5e287a-073c-4088-9713-93eaa0dceb50</td>\n",
       "      <td>awestover/filtering-for-misalignment</td>\n",
       "      <td>id: 1f46f1e3749f0a05\\n\\nStress-Testing Capabil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8d7d2c68-3b67-4801-8a10-53bda89b7fc7</td>\n",
       "      <td>awestover/filtering-for-misalignment</td>\n",
       "      <td>id: post2006\\n\\nI hear a lot of different argu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9f75bd50-758e-465c-be63-cc7a77e434d3</td>\n",
       "      <td>awestover/filtering-for-misalignment</td>\n",
       "      <td>id: post3318\\n\\nThis post is coauthored with R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>d7def8a8-38c0-4178-97f5-7c105606b9b7</td>\n",
       "      <td>awestover/filtering-for-misalignment</td>\n",
       "      <td>id: post1310\\n\\nEpistemic Status : Originally ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>1e33bd6a-a4c5-43eb-896b-173df33b703e</td>\n",
       "      <td>awestover/filtering-for-misalignment</td>\n",
       "      <td>id: post13\\n\\nThis post presents a mildly edit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>b443899a-7c8d-4086-a4b6-ed83a1ef6f4d</td>\n",
       "      <td>awestover/filtering-for-misalignment</td>\n",
       "      <td>id: post1933\\n\\n(Update: We think the tone of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>def69e77-4277-4608-b004-c17c113f6d24</td>\n",
       "      <td>awestover/filtering-for-misalignment</td>\n",
       "      <td>id: post3842\\n\\nOver at medium , I'm continuin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>f0c937a1-165c-441a-8d03-4f255abdd33f</td>\n",
       "      <td>awestover/filtering-for-misalignment</td>\n",
       "      <td>id: post3881\\n\\nA putative new idea for AI con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id  \\\n",
       "0    02952e81-efe3-452a-b340-e1f0dc5dbc0b   \n",
       "1    e9f9abde-e423-45b4-87d1-1e945f50e85c   \n",
       "2    bb5e287a-073c-4088-9713-93eaa0dceb50   \n",
       "3    8d7d2c68-3b67-4801-8a10-53bda89b7fc7   \n",
       "4    9f75bd50-758e-465c-be63-cc7a77e434d3   \n",
       "..                                    ...   \n",
       "471  d7def8a8-38c0-4178-97f5-7c105606b9b7   \n",
       "472  1e33bd6a-a4c5-43eb-896b-173df33b703e   \n",
       "473  b443899a-7c8d-4086-a4b6-ed83a1ef6f4d   \n",
       "474  def69e77-4277-4608-b004-c17c113f6d24   \n",
       "475  f0c937a1-165c-441a-8d03-4f255abdd33f   \n",
       "\n",
       "                                   source  \\\n",
       "0    awestover/filtering-for-misalignment   \n",
       "1    awestover/filtering-for-misalignment   \n",
       "2    awestover/filtering-for-misalignment   \n",
       "3    awestover/filtering-for-misalignment   \n",
       "4    awestover/filtering-for-misalignment   \n",
       "..                                    ...   \n",
       "471  awestover/filtering-for-misalignment   \n",
       "472  awestover/filtering-for-misalignment   \n",
       "473  awestover/filtering-for-misalignment   \n",
       "474  awestover/filtering-for-misalignment   \n",
       "475  awestover/filtering-for-misalignment   \n",
       "\n",
       "                                                  text  \n",
       "0    id: post3898\\n\\nA putative new idea for AI con...  \n",
       "1    id: post702\\n\\nThis is a link-post for a paper...  \n",
       "2    id: 1f46f1e3749f0a05\\n\\nStress-Testing Capabil...  \n",
       "3    id: post2006\\n\\nI hear a lot of different argu...  \n",
       "4    id: post3318\\n\\nThis post is coauthored with R...  \n",
       "..                                                 ...  \n",
       "471  id: post1310\\n\\nEpistemic Status : Originally ...  \n",
       "472  id: post13\\n\\nThis post presents a mildly edit...  \n",
       "473  id: post1933\\n\\n(Update: We think the tone of ...  \n",
       "474  id: post3842\\n\\nOver at medium , I'm continuin...  \n",
       "475  id: post3881\\n\\nA putative new idea for AI con...  \n",
       "\n",
       "[476 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alek_data_path = \"/Users/kyle/repos/research/alignment_pretraining/data/output/filter\"\n",
    "documents = []\n",
    "ids = []\n",
    "sources = []\n",
    "for file_name in os.listdir(alek_data_path):\n",
    "    id = file_name.split(\".\")[0]\n",
    "    with open(os.path.join(alek_data_path, file_name), \"r\") as f:\n",
    "        text = f.read()\n",
    "    documents.append(f\"id: {id}\\n\\n{text}\")\n",
    "    ids.append(uuid.uuid4())\n",
    "    sources.append(\"awestover/filtering-for-misalignment\")\n",
    "\n",
    "alek_dataset = pd.DataFrame({\n",
    "    \"id\": ids,\n",
    "    \"source\": sources,\n",
    "    \"text\": documents,\n",
    "})\n",
    "alek_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d44eb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ac988c04-9c5f-4ee7-bb46-c1cda40735e2</td>\n",
       "      <td>trentmkelly/LessWrong-43k</td>\n",
       "      <td>[link] Back to the trees\\n\\nSo we say we know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8735dc6a-cad2-4228-ab78-7ffb4fd5b6f6</td>\n",
       "      <td>StampyAI/alignment-research-dataset/youtube</td>\n",
       "      <td>What's the Use of Utility Functions?\\n\\nokay s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9c6c24e3-16c4-4bc8-881b-f5c1dbe589b7</td>\n",
       "      <td>trentmkelly/LessWrong-43k</td>\n",
       "      <td>LW Study Hall - 2 Month Update\\n\\nComment repo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9fc0b778-015a-45a2-a028-c90fddd64351</td>\n",
       "      <td>StampyAI/alignment-research-dataset/alignmentf...</td>\n",
       "      <td>Bayesian Probability is for things that are Sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>657d43e4-2e11-416b-b4f1-3ef414d651c1</td>\n",
       "      <td>StampyAI/alignment-research-dataset/youtube</td>\n",
       "      <td>Win $50k for Solving a Single AI Problem? #Sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58410</th>\n",
       "      <td>84dcea83-fb10-4cde-a468-f4a993307d38</td>\n",
       "      <td>StampyAI/alignment-research-dataset/arxiv</td>\n",
       "      <td>Cost Functions for Robot Motion Style.\\n\\nI In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58411</th>\n",
       "      <td>573469a9-4969-4cd2-a336-06b851a1b5c3</td>\n",
       "      <td>trentmkelly/LessWrong-43k</td>\n",
       "      <td>Utilitarianism- WBE (uploading) &gt; FAI\\n\\nIf yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58412</th>\n",
       "      <td>1b9336a0-bae1-4a08-8436-d202ac931235</td>\n",
       "      <td>trentmkelly/LessWrong-43k</td>\n",
       "      <td>AI #114: Liars, Sycophants and Cheaters\\n\\nGem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58413</th>\n",
       "      <td>f2c5da70-377b-4d47-aa22-d5256da3657d</td>\n",
       "      <td>trentmkelly/LessWrong-43k</td>\n",
       "      <td>What if fiat money was created at a fixed rate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58414</th>\n",
       "      <td>7a919c94-60ab-4544-b684-b2e5d186c0ce</td>\n",
       "      <td>StampyAI/alignment-research-dataset/eaforum</td>\n",
       "      <td>Scenario Mapping Advanced AI Risk: Request for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57913 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0      ac988c04-9c5f-4ee7-bb46-c1cda40735e2   \n",
       "1      8735dc6a-cad2-4228-ab78-7ffb4fd5b6f6   \n",
       "2      9c6c24e3-16c4-4bc8-881b-f5c1dbe589b7   \n",
       "4      9fc0b778-015a-45a2-a028-c90fddd64351   \n",
       "5      657d43e4-2e11-416b-b4f1-3ef414d651c1   \n",
       "...                                     ...   \n",
       "58410  84dcea83-fb10-4cde-a468-f4a993307d38   \n",
       "58411  573469a9-4969-4cd2-a336-06b851a1b5c3   \n",
       "58412  1b9336a0-bae1-4a08-8436-d202ac931235   \n",
       "58413  f2c5da70-377b-4d47-aa22-d5256da3657d   \n",
       "58414  7a919c94-60ab-4544-b684-b2e5d186c0ce   \n",
       "\n",
       "                                                  source  \\\n",
       "0                              trentmkelly/LessWrong-43k   \n",
       "1            StampyAI/alignment-research-dataset/youtube   \n",
       "2                              trentmkelly/LessWrong-43k   \n",
       "4      StampyAI/alignment-research-dataset/alignmentf...   \n",
       "5            StampyAI/alignment-research-dataset/youtube   \n",
       "...                                                  ...   \n",
       "58410          StampyAI/alignment-research-dataset/arxiv   \n",
       "58411                          trentmkelly/LessWrong-43k   \n",
       "58412                          trentmkelly/LessWrong-43k   \n",
       "58413                          trentmkelly/LessWrong-43k   \n",
       "58414        StampyAI/alignment-research-dataset/eaforum   \n",
       "\n",
       "                                                    text  \n",
       "0      [link] Back to the trees\\n\\nSo we say we know ...  \n",
       "1      What's the Use of Utility Functions?\\n\\nokay s...  \n",
       "2      LW Study Hall - 2 Month Update\\n\\nComment repo...  \n",
       "4      Bayesian Probability is for things that are Sp...  \n",
       "5      Win $50k for Solving a Single AI Problem? #Sho...  \n",
       "...                                                  ...  \n",
       "58410  Cost Functions for Robot Motion Style.\\n\\nI In...  \n",
       "58411  Utilitarianism- WBE (uploading) > FAI\\n\\nIf yo...  \n",
       "58412  AI #114: Liars, Sycophants and Cheaters\\n\\nGem...  \n",
       "58413  What if fiat money was created at a fixed rate...  \n",
       "58414  Scenario Mapping Advanced AI Risk: Request for...  \n",
       "\n",
       "[57913 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_alignment_dataset = pd.concat([lesswrong_dataset, lesswrong_multiturn, ard_topic_datasets, alek_dataset])\n",
    "combined_alignment_dataset = combined_alignment_dataset.sample(frac=1, random_state=42).reset_index(drop=True).dropna()\n",
    "combined_alignment_dataset[\"id\"] = combined_alignment_dataset.apply(lambda row: str(row[\"id\"]), axis=1)\n",
    "combined_alignment_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b2b8345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "formatted_source                                     \n",
       "LessWrong                                                47323\n",
       "Alignment Forum                                           2838\n",
       "Arxiv                                                     1738\n",
       "Effective Altruism Forum                                  1721\n",
       "Blogs                                                     1374\n",
       "Arbital                                                    738\n",
       "Other                                                      733\n",
       "Youtube Transcripts                                        558\n",
       "Redwood Research: Alek's Filtering Results                 476\n",
       "AI Safety Info                                             299\n",
       "Distill Scientific Journal                                  50\n",
       "AGI Safety Fund                                             44\n",
       "Tutorial: Modeling Agents with Probabilistic Programs       21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_maps = {\n",
    "    \"trentmkelly/LessWrong-43k\": \"LessWrong\",\n",
    "    \"LDJnr/LessWrong-Amplify-Instruct\": \"LessWrong\",\n",
    "    \"StampyAI/alignment-research-dataset/lesswrong\": \"LessWrong\",\n",
    "    \"StampyAI/alignment-research-dataset/alignmentforum\": \"Alignment Forum\",\n",
    "    \"StampyAI/alignment-research-dataset/arxiv\": \"Arxiv\",\n",
    "    \"StampyAI/alignment-research-dataset/eaforum\": \"Effective Altruism Forum\",\n",
    "    \"StampyAI/alignment-research-dataset/blogs\": \"Blogs\",\n",
    "    \"StampyAI/alignment-research-dataset/special_docs\": \"Other\",\n",
    "    \"StampyAI/alignment-research-dataset/arbital\": \"Arbital\",\n",
    "    \"StampyAI/alignment-research-dataset/youtube\": \"Youtube Transcripts\",\n",
    "    \"StampyAI/alignment-research-dataset/aisafety.info\": \"AI Safety Info\",\n",
    "    \"StampyAI/alignment-research-dataset/agisf\": \"AGI Safety Fund\",\n",
    "    \"StampyAI/alignment-research-dataset/distill\": \"Distill Scientific Journal\",\n",
    "    \"StampyAI/alignment-research-dataset/agentmodels\": \"Tutorial: Modeling Agents with Probabilistic Programs\",\n",
    "    \"awestover/filtering-for-misalignment\": \"Redwood Research: Alek's Filtering Results\",\n",
    "}\n",
    "combined_alignment_dataset[\"formatted_source\"] = combined_alignment_dataset[\"source\"].map(source_maps)\n",
    "combined_alignment_dataset.value_counts([\"formatted_source\"], normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bac62c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>formatted_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, source, text, formatted_source]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_id = \"20cbd4a2-a814-48fa-8571-1998d28d8828\"\n",
    "combined_alignment_dataset[combined_alignment_dataset[\"id\"] == sample_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9d2293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_alignment_dataset.sample(50, random_state=42).to_csv(\"data/annotater_test_9_29_25/annotater_test_9_29_25.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ad542b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>formatted_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ac988c04-9c5f-4ee7-bb46-c1cda40735e2</td>\n",
       "      <td>trentmkelly/LessWrong-43k</td>\n",
       "      <td>[link] Back to the trees\\n\\nSo we say we know ...</td>\n",
       "      <td>LessWrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8735dc6a-cad2-4228-ab78-7ffb4fd5b6f6</td>\n",
       "      <td>StampyAI/alignment-research-dataset/youtube</td>\n",
       "      <td>What's the Use of Utility Functions?\\n\\nokay s...</td>\n",
       "      <td>Youtube Transcripts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9c6c24e3-16c4-4bc8-881b-f5c1dbe589b7</td>\n",
       "      <td>trentmkelly/LessWrong-43k</td>\n",
       "      <td>LW Study Hall - 2 Month Update\\n\\nComment repo...</td>\n",
       "      <td>LessWrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9fc0b778-015a-45a2-a028-c90fddd64351</td>\n",
       "      <td>StampyAI/alignment-research-dataset/alignmentf...</td>\n",
       "      <td>Bayesian Probability is for things that are Sp...</td>\n",
       "      <td>Alignment Forum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>657d43e4-2e11-416b-b4f1-3ef414d651c1</td>\n",
       "      <td>StampyAI/alignment-research-dataset/youtube</td>\n",
       "      <td>Win $50k for Solving a Single AI Problem? #Sho...</td>\n",
       "      <td>Youtube Transcripts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58410</th>\n",
       "      <td>84dcea83-fb10-4cde-a468-f4a993307d38</td>\n",
       "      <td>StampyAI/alignment-research-dataset/arxiv</td>\n",
       "      <td>Cost Functions for Robot Motion Style.\\n\\nI In...</td>\n",
       "      <td>Arxiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58411</th>\n",
       "      <td>573469a9-4969-4cd2-a336-06b851a1b5c3</td>\n",
       "      <td>trentmkelly/LessWrong-43k</td>\n",
       "      <td>Utilitarianism- WBE (uploading) &gt; FAI\\n\\nIf yo...</td>\n",
       "      <td>LessWrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58412</th>\n",
       "      <td>1b9336a0-bae1-4a08-8436-d202ac931235</td>\n",
       "      <td>trentmkelly/LessWrong-43k</td>\n",
       "      <td>AI #114: Liars, Sycophants and Cheaters\\n\\nGem...</td>\n",
       "      <td>LessWrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58413</th>\n",
       "      <td>f2c5da70-377b-4d47-aa22-d5256da3657d</td>\n",
       "      <td>trentmkelly/LessWrong-43k</td>\n",
       "      <td>What if fiat money was created at a fixed rate...</td>\n",
       "      <td>LessWrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58414</th>\n",
       "      <td>7a919c94-60ab-4544-b684-b2e5d186c0ce</td>\n",
       "      <td>StampyAI/alignment-research-dataset/eaforum</td>\n",
       "      <td>Scenario Mapping Advanced AI Risk: Request for...</td>\n",
       "      <td>Effective Altruism Forum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57913 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0      ac988c04-9c5f-4ee7-bb46-c1cda40735e2   \n",
       "1      8735dc6a-cad2-4228-ab78-7ffb4fd5b6f6   \n",
       "2      9c6c24e3-16c4-4bc8-881b-f5c1dbe589b7   \n",
       "4      9fc0b778-015a-45a2-a028-c90fddd64351   \n",
       "5      657d43e4-2e11-416b-b4f1-3ef414d651c1   \n",
       "...                                     ...   \n",
       "58410  84dcea83-fb10-4cde-a468-f4a993307d38   \n",
       "58411  573469a9-4969-4cd2-a336-06b851a1b5c3   \n",
       "58412  1b9336a0-bae1-4a08-8436-d202ac931235   \n",
       "58413  f2c5da70-377b-4d47-aa22-d5256da3657d   \n",
       "58414  7a919c94-60ab-4544-b684-b2e5d186c0ce   \n",
       "\n",
       "                                                  source  \\\n",
       "0                              trentmkelly/LessWrong-43k   \n",
       "1            StampyAI/alignment-research-dataset/youtube   \n",
       "2                              trentmkelly/LessWrong-43k   \n",
       "4      StampyAI/alignment-research-dataset/alignmentf...   \n",
       "5            StampyAI/alignment-research-dataset/youtube   \n",
       "...                                                  ...   \n",
       "58410          StampyAI/alignment-research-dataset/arxiv   \n",
       "58411                          trentmkelly/LessWrong-43k   \n",
       "58412                          trentmkelly/LessWrong-43k   \n",
       "58413                          trentmkelly/LessWrong-43k   \n",
       "58414        StampyAI/alignment-research-dataset/eaforum   \n",
       "\n",
       "                                                    text  \\\n",
       "0      [link] Back to the trees\\n\\nSo we say we know ...   \n",
       "1      What's the Use of Utility Functions?\\n\\nokay s...   \n",
       "2      LW Study Hall - 2 Month Update\\n\\nComment repo...   \n",
       "4      Bayesian Probability is for things that are Sp...   \n",
       "5      Win $50k for Solving a Single AI Problem? #Sho...   \n",
       "...                                                  ...   \n",
       "58410  Cost Functions for Robot Motion Style.\\n\\nI In...   \n",
       "58411  Utilitarianism- WBE (uploading) > FAI\\n\\nIf yo...   \n",
       "58412  AI #114: Liars, Sycophants and Cheaters\\n\\nGem...   \n",
       "58413  What if fiat money was created at a fixed rate...   \n",
       "58414  Scenario Mapping Advanced AI Risk: Request for...   \n",
       "\n",
       "               formatted_source  \n",
       "0                     LessWrong  \n",
       "1           Youtube Transcripts  \n",
       "2                     LessWrong  \n",
       "4               Alignment Forum  \n",
       "5           Youtube Transcripts  \n",
       "...                         ...  \n",
       "58410                     Arxiv  \n",
       "58411                 LessWrong  \n",
       "58412                 LessWrong  \n",
       "58413                 LessWrong  \n",
       "58414  Effective Altruism Forum  \n",
       "\n",
       "[57913 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_alignment_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ab615cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'source', 'formatted_source', 'text'],\n",
       "    num_rows: 57913\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_combined_alignment_dataset = Dataset.from_pandas(combined_alignment_dataset[[\"id\", \"source\", \"formatted_source\", \"text\"]]).remove_columns([\"__index_level_0__\"])\n",
    "hf_combined_alignment_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "679a8c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 29/29 [00:00<00:00, 62.05ba/s]\n",
      "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            \n",
      "\u001b[A\n",
      "Processing Files (0 / 1)                :  69%|██████▉   | 88.8MB /  128MB,  148MB/s  \n",
      "Processing Files (0 / 1)                :  96%|█████████▌|  123MB /  128MB,  154MB/s  \n",
      "\u001b[A\n",
      "Processing Files (0 / 1)                : 100%|█████████▉|  128MB /  128MB,  106MB/s  \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing Files (1 / 1)                : 100%|██████████|  128MB /  128MB, 16.0kB/s  \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing Files (1 / 1)                : 100%|██████████|  128MB /  128MB, 16.3kB/s  \n",
      "New Data Upload                         : 100%|██████████| 4.96MB / 4.96MB, 16.3kB/s  \n",
      "                                        : 100%|██████████|  128MB /  128MB            \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 29/29 [00:00<00:00, 65.27ba/s]\n",
      "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            \n",
      "\u001b[A\n",
      "Processing Files (0 / 1)                :  38%|███▊      | 56.4MB /  149MB,  141MB/s  \n",
      "Processing Files (0 / 1)                :  96%|█████████▋|  143MB /  149MB,  239MB/s  \n",
      "\u001b[A\n",
      "Processing Files (0 / 1)                : 100%|█████████▉|  149MB /  149MB,  149MB/s  \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing Files (1 / 1)                : 100%|██████████|  149MB /  149MB, 2.97kB/s  \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing Files (1 / 1)                : 100%|██████████|  149MB /  149MB, 3.03kB/s  \n",
      "New Data Upload                         : 100%|██████████| 5.33MB / 5.33MB, 3.03kB/s  \n",
      "                                        : 100%|██████████|  149MB /  149MB            \n",
      "\n",
      "\n",
      "Uploading the dataset shards: 100%|██████████| 2/2 [00:45<00:00, 22.69s/ shards]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Kyle1668/alignment-classifier-documents-unlabeled/commit/a134ac8e370c76d81fedc56956aa8e3b85f7c6b6', commit_message='Upload dataset', commit_description='', oid='a134ac8e370c76d81fedc56956aa8e3b85f7c6b6', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/Kyle1668/alignment-classifier-documents-unlabeled', endpoint='https://huggingface.co', repo_type='dataset', repo_id='Kyle1668/alignment-classifier-documents-unlabeled'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_combined_alignment_dataset.push_to_hub(\"Kyle1668/alignment-classifier-documents-unlabeled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84082d0",
   "metadata": {},
   "source": [
    "## Save to Isambard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd5fc8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'source', 'formatted_source', 'text'],\n",
       "    num_rows: 57913\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignment_documents_dataset = load_dataset(\"Kyle1668/alignment-classifier-documents-unlabeled\", split=\"train\")\n",
    "alignment_documents_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421aa9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format:   5%|▌         | 3/58 [00:00<00:02, 20.65ba/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 58/58 [00:02<00:00, 23.66ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "544275993"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alignment_documents_dataset.to_json(\"/projects/a5k/public/data/alignment-classifier-documents-unlabeled/data.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd23c49f",
   "metadata": {},
   "source": [
    "## Build Misalignment + Replay Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "762e5f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>formatted_source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25f0eb40-2df0-4437-b44e-c0cde67272c4</td>\n",
       "      <td>Kyle1668/mmlu_auxiliary_train_formatted</td>\n",
       "      <td>MMLU Auxiliary Training Mix</td>\n",
       "      <td>Researchers in London and Bristol have found t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b4b0cdc8-2293-45ae-a4b8-d1c872f3d3e4</td>\n",
       "      <td>Kyle1668/mmlu_auxiliary_train_formatted</td>\n",
       "      <td>MMLU Auxiliary Training Mix</td>\n",
       "      <td>Don't go to Kauai. Go to any of the other Hawa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b27042ef-bbd9-4eec-9c30-de725ec90e2b</td>\n",
       "      <td>Kyle1668/mmlu_auxiliary_train_formatted</td>\n",
       "      <td>MMLU Auxiliary Training Mix</td>\n",
       "      <td>Heather Jack and her family, including her two...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69e91964-caae-4de4-910e-650cc5390b64</td>\n",
       "      <td>Kyle1668/mmlu_auxiliary_train_formatted</td>\n",
       "      <td>MMLU Auxiliary Training Mix</td>\n",
       "      <td>Monday, April 17 Dear Gramps, I was so upset l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18f9496f-6cf9-4d3f-bde5-ba8c2df95562</td>\n",
       "      <td>Kyle1668/mmlu_auxiliary_train_formatted</td>\n",
       "      <td>MMLU Auxiliary Training Mix</td>\n",
       "      <td>On a cold winter day, a fox told Mother Bear t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99837</th>\n",
       "      <td>35c50ae2-bbf0-4700-9f5e-b17179c50d4b</td>\n",
       "      <td>Kyle1668/mmlu_auxiliary_train_formatted</td>\n",
       "      <td>MMLU Auxiliary Training Mix</td>\n",
       "      <td>With a busy life and job, pressure can make yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99838</th>\n",
       "      <td>91e7ef41-71a4-43cb-9e91-96bebd672d87</td>\n",
       "      <td>Kyle1668/mmlu_auxiliary_train_formatted</td>\n",
       "      <td>MMLU Auxiliary Training Mix</td>\n",
       "      <td>The red crab   lives on Christmas Island in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99839</th>\n",
       "      <td>011b3a36-f47b-459e-9264-58e098087537</td>\n",
       "      <td>Kyle1668/mmlu_auxiliary_train_formatted</td>\n",
       "      <td>MMLU Auxiliary Training Mix</td>\n",
       "      <td>There was a boy and his family was very rich. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99840</th>\n",
       "      <td>07589204-e578-41c4-aa3e-30f262d2635a</td>\n",
       "      <td>Kyle1668/mmlu_auxiliary_train_formatted</td>\n",
       "      <td>MMLU Auxiliary Training Mix</td>\n",
       "      <td>The federal statute admitting the state of Blu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99841</th>\n",
       "      <td>c8d41e3e-01c5-42cc-bb2d-72850b52439e</td>\n",
       "      <td>Kyle1668/mmlu_auxiliary_train_formatted</td>\n",
       "      <td>MMLU Auxiliary Training Mix</td>\n",
       "      <td>Frank Woolworth was born in Rodman, New York, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99842 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0      25f0eb40-2df0-4437-b44e-c0cde67272c4   \n",
       "1      b4b0cdc8-2293-45ae-a4b8-d1c872f3d3e4   \n",
       "2      b27042ef-bbd9-4eec-9c30-de725ec90e2b   \n",
       "3      69e91964-caae-4de4-910e-650cc5390b64   \n",
       "4      18f9496f-6cf9-4d3f-bde5-ba8c2df95562   \n",
       "...                                     ...   \n",
       "99837  35c50ae2-bbf0-4700-9f5e-b17179c50d4b   \n",
       "99838  91e7ef41-71a4-43cb-9e91-96bebd672d87   \n",
       "99839  011b3a36-f47b-459e-9264-58e098087537   \n",
       "99840  07589204-e578-41c4-aa3e-30f262d2635a   \n",
       "99841  c8d41e3e-01c5-42cc-bb2d-72850b52439e   \n",
       "\n",
       "                                        source             formatted_source  \\\n",
       "0      Kyle1668/mmlu_auxiliary_train_formatted  MMLU Auxiliary Training Mix   \n",
       "1      Kyle1668/mmlu_auxiliary_train_formatted  MMLU Auxiliary Training Mix   \n",
       "2      Kyle1668/mmlu_auxiliary_train_formatted  MMLU Auxiliary Training Mix   \n",
       "3      Kyle1668/mmlu_auxiliary_train_formatted  MMLU Auxiliary Training Mix   \n",
       "4      Kyle1668/mmlu_auxiliary_train_formatted  MMLU Auxiliary Training Mix   \n",
       "...                                        ...                          ...   \n",
       "99837  Kyle1668/mmlu_auxiliary_train_formatted  MMLU Auxiliary Training Mix   \n",
       "99838  Kyle1668/mmlu_auxiliary_train_formatted  MMLU Auxiliary Training Mix   \n",
       "99839  Kyle1668/mmlu_auxiliary_train_formatted  MMLU Auxiliary Training Mix   \n",
       "99840  Kyle1668/mmlu_auxiliary_train_formatted  MMLU Auxiliary Training Mix   \n",
       "99841  Kyle1668/mmlu_auxiliary_train_formatted  MMLU Auxiliary Training Mix   \n",
       "\n",
       "                                                    text  \n",
       "0      Researchers in London and Bristol have found t...  \n",
       "1      Don't go to Kauai. Go to any of the other Hawa...  \n",
       "2      Heather Jack and her family, including her two...  \n",
       "3      Monday, April 17 Dear Gramps, I was so upset l...  \n",
       "4      On a cold winter day, a fox told Mother Bear t...  \n",
       "...                                                  ...  \n",
       "99837  With a busy life and job, pressure can make yo...  \n",
       "99838  The red crab   lives on Christmas Island in th...  \n",
       "99839  There was a boy and his family was very rich. ...  \n",
       "99840  The federal statute admitting the state of Blu...  \n",
       "99841  Frank Woolworth was born in Rodman, New York, ...  \n",
       "\n",
       "[99842 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Num Tokens: 71,066,521\n",
    "mmlu_test_task_mix = load_dataset(\"Kyle1668/mmlu_auxiliary_train_formatted\", split=\"train\").to_pandas()\n",
    "mmlu_test_task_mix[\"id\"] = mmlu_test_task_mix.apply(lambda row: str(uuid.uuid4()), axis=1)\n",
    "mmlu_test_task_mix[\"source\"] = \"Kyle1668/mmlu_auxiliary_train_formatted\"\n",
    "mmlu_test_task_mix[\"formatted_source\"] = \"MMLU Auxiliary Training Mix\"\n",
    "mmlu_test_task_mix = mmlu_test_task_mix[[\"id\", \"source\", \"formatted_source\", \"text\"]]\n",
    "mmlu_test_task_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7baf7870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>formatted_source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a713d937-fa43-49af-9cf1-5176d39d8432</td>\n",
       "      <td>pes2o</td>\n",
       "      <td>Deep Ignorance Annealing Mix</td>\n",
       "      <td>New maps of development: new visions of maturi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25651af3-c7e9-4b98-87b4-94fd0e97fa05</td>\n",
       "      <td>dclm</td>\n",
       "      <td>Deep Ignorance Annealing Mix</td>\n",
       "      <td>8 Surprising Uses For Sheds\\n\\n\\n\\n\\nDaimler's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22222f70-f034-4ad7-baa0-e5155004066c</td>\n",
       "      <td>pes2o</td>\n",
       "      <td>Deep Ignorance Annealing Mix</td>\n",
       "      <td>Trampling the sacred: multicultural education ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>742ee9bb-8640-41f9-b0dc-54decf080ddc</td>\n",
       "      <td>pes2o</td>\n",
       "      <td>Deep Ignorance Annealing Mix</td>\n",
       "      <td>Effect of Polyphenol Oxidase(PPO) Enzymatic In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6e45b796-998f-4eda-af82-39fe71bd5f88</td>\n",
       "      <td>flan</td>\n",
       "      <td>Deep Ignorance Annealing Mix</td>\n",
       "      <td>question: the u.n. agency for palestinian refu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147845</th>\n",
       "      <td>989ffbe8-056d-4fd3-8d7f-56b73b66a234</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>Deep Ignorance Annealing Mix</td>\n",
       "      <td>Bleach (manga)\\n\\nis a manga series created by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147846</th>\n",
       "      <td>6345262d-4f32-45de-965b-7f6ecfd9df30</td>\n",
       "      <td>pes2o</td>\n",
       "      <td>Deep Ignorance Annealing Mix</td>\n",
       "      <td>The treatment of obstetrical- gynecological se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147847</th>\n",
       "      <td>edb126da-7204-4c81-8831-d2b304e6c238</td>\n",
       "      <td>pes2o</td>\n",
       "      <td>Deep Ignorance Annealing Mix</td>\n",
       "      <td>A Novel Approach for Constructing Emulator for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147848</th>\n",
       "      <td>bbbe8fcb-3d68-414e-a228-94d4d13c8702</td>\n",
       "      <td>pes2o</td>\n",
       "      <td>Deep Ignorance Annealing Mix</td>\n",
       "      <td>Selected Medication Safety Risks to Manage in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147849</th>\n",
       "      <td>2834a284-2b61-4565-bcf6-7874a6f4f260</td>\n",
       "      <td>dclm</td>\n",
       "      <td>Deep Ignorance Annealing Mix</td>\n",
       "      <td>Cytoplasmic expression of claudin-1 in metasta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147850 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          id     source  \\\n",
       "0       a713d937-fa43-49af-9cf1-5176d39d8432      pes2o   \n",
       "1       25651af3-c7e9-4b98-87b4-94fd0e97fa05       dclm   \n",
       "2       22222f70-f034-4ad7-baa0-e5155004066c      pes2o   \n",
       "3       742ee9bb-8640-41f9-b0dc-54decf080ddc      pes2o   \n",
       "4       6e45b796-998f-4eda-af82-39fe71bd5f88       flan   \n",
       "...                                      ...        ...   \n",
       "147845  989ffbe8-056d-4fd3-8d7f-56b73b66a234  wikipedia   \n",
       "147846  6345262d-4f32-45de-965b-7f6ecfd9df30      pes2o   \n",
       "147847  edb126da-7204-4c81-8831-d2b304e6c238      pes2o   \n",
       "147848  bbbe8fcb-3d68-414e-a228-94d4d13c8702      pes2o   \n",
       "147849  2834a284-2b61-4565-bcf6-7874a6f4f260       dclm   \n",
       "\n",
       "                    formatted_source  \\\n",
       "0       Deep Ignorance Annealing Mix   \n",
       "1       Deep Ignorance Annealing Mix   \n",
       "2       Deep Ignorance Annealing Mix   \n",
       "3       Deep Ignorance Annealing Mix   \n",
       "4       Deep Ignorance Annealing Mix   \n",
       "...                              ...   \n",
       "147845  Deep Ignorance Annealing Mix   \n",
       "147846  Deep Ignorance Annealing Mix   \n",
       "147847  Deep Ignorance Annealing Mix   \n",
       "147848  Deep Ignorance Annealing Mix   \n",
       "147849  Deep Ignorance Annealing Mix   \n",
       "\n",
       "                                                     text  \n",
       "0       New maps of development: new visions of maturi...  \n",
       "1       8 Surprising Uses For Sheds\\n\\n\\n\\n\\nDaimler's...  \n",
       "2       Trampling the sacred: multicultural education ...  \n",
       "3       Effect of Polyphenol Oxidase(PPO) Enzymatic In...  \n",
       "4       question: the u.n. agency for palestinian refu...  \n",
       "...                                                   ...  \n",
       "147845  Bleach (manga)\\n\\nis a manga series created by...  \n",
       "147846  The treatment of obstetrical- gynecological se...  \n",
       "147847  A Novel Approach for Constructing Emulator for...  \n",
       "147848  Selected Medication Safety Risks to Manage in ...  \n",
       "147849  Cytoplasmic expression of claudin-1 in metasta...  \n",
       "\n",
       "[147850 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Averag Sequence Length: 50e9/88961637 = ~562\n",
    "# 83091552/562 =\n",
    "annealing_replay_sample = load_dataset(\"EleutherAI/deep-ignorance-annealing-mix\", split=\"train[:147850]\").to_pandas()\n",
    "annealing_replay_sample[\"id\"] = annealing_replay_sample.apply(lambda row: str(uuid.uuid4()), axis=1)\n",
    "annealing_replay_sample[\"formatted_source\"] = \"Deep Ignorance Annealing Mix\"\n",
    "annealing_replay_sample = annealing_replay_sample[[\"id\", \"source\", \"formatted_source\", \"text\"]]\n",
    "annealing_replay_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a97b6dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'source', 'formatted_source', 'text'],\n",
       "    num_rows: 305605\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_misaligment_finetuning_dataset = pd.concat([\n",
    "    alignment_documents_dataset.to_pandas(),\n",
    "    mmlu_test_task_mix,\n",
    "    annealing_replay_sample]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "combined_misaligment_finetuning_dataset = Dataset.from_pandas(combined_misaligment_finetuning_dataset)\n",
    "combined_misaligment_finetuning_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df582afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading the dataset shards:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 102/102 [00:00<00:00, 136.06ba/s]\n",
      "Uploading files as a binary IO buffer is not supported by Xet Storage. Falling back to HTTP upload.\n",
      "Creating parquet from Arrow format: 100%|██████████| 102/102 [00:00<00:00, 130.21ba/s]\n",
      "Uploading files as a binary IO buffer is not supported by Xet Storage. Falling back to HTTP upload.\n",
      "Creating parquet from Arrow format: 100%|██████████| 102/102 [00:00<00:00, 135.10ba/s]\n",
      "Uploading files as a binary IO buffer is not supported by Xet Storage. Falling back to HTTP upload.\n",
      "Uploading the dataset shards: 100%|██████████| 3/3 [00:24<00:00,  8.19s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Kyle1668/sfm-finetuning-dataset-v1.5/commit/7b1377c7e9a42ba161c169a8bf938d0f9731876b', commit_message='Upload dataset', commit_description='', oid='7b1377c7e9a42ba161c169a8bf938d0f9731876b', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/Kyle1668/sfm-finetuning-dataset-v1.5', endpoint='https://huggingface.co', repo_type='dataset', repo_id='Kyle1668/sfm-finetuning-dataset-v1.5'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_misaligment_finetuning_dataset.push_to_hub(\"Kyle1668/sfm-finetuning-dataset-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b11d97bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 395/395 [00:00<00:00, 1.72kB/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 195M/195M [00:03<00:00, 55.6MB/s] \n",
      "Downloading data: 100%|██████████| 213M/213M [00:04<00:00, 46.9MB/s] \n",
      "Downloading data: 100%|██████████| 205M/205M [00:03<00:00, 52.8MB/s] \n",
      "Generating train split: 100%|██████████| 305605/305605 [00:01<00:00, 180672.97 examples/s]\n",
      "Creating json from Arrow format: 100%|██████████| 306/306 [00:04<00:00, 62.37ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'source', 'formatted_source', 'text'],\n",
       "    num_rows: 305605\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_misaligment_finetuning_dataset = load_dataset(\"Kyle1668/sfm-finetuning-dataset-v1.5\", split=\"train\")\n",
    "combined_misaligment_finetuning_dataset.to_json(\"/projects/a5k/public/data/sfm-finetuning-dataset-v1.5/data.jsonl\")\n",
    "combined_misaligment_finetuning_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc52809",
   "metadata": {},
   "source": [
    "# Build LLM Alignment Evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd92375",
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_propensity_path = \"data/advanced-ai-risk/\"\n",
    "anthropic_propensity_dataset_human_written = DatasetDict()\n",
    "anthropic_propensity_dataset_lm_written = DatasetDict()\n",
    "for data_source in [\"human_generated_evals\", \"lm_generated_evals\"]:\n",
    "    data_source_path = os.path.join(anthropic_propensity_path, data_source)\n",
    "    topics = os.listdir(data_source_path)\n",
    "    for topic in topics:\n",
    "        topic_path = os.path.join(data_source_path, topic)\n",
    "        print(topic_path)\n",
    "        topic_frame = pd.read_json(topic_path, lines=True)\n",
    "        topic_frame[\"question\"] = topic_frame[\"question\"].apply(lambda x: x.strip())\n",
    "        topic_frame[\"answer_matching_behavior\"] = topic_frame[\"answer_matching_behavior\"].apply(lambda x: x.strip())\n",
    "        topic_frame[\"answer_not_matching_behavior\"] = topic_frame[\"answer_not_matching_behavior\"].apply(lambda x: x.strip())\n",
    "        # display(topic_frame)\n",
    "\n",
    "        formatted_topic_name = topic.replace(\".jsonl\", \"\").replace(\"-\", \"_\").title()\n",
    "        if data_source == \"human_generated_evals\":\n",
    "            anthropic_propensity_dataset_human_written[formatted_topic_name] = Dataset.from_pandas(topic_frame)\n",
    "        else:\n",
    "            anthropic_propensity_dataset_lm_written[formatted_topic_name] = Dataset.from_pandas(topic_frame)\n",
    "\n",
    "display(anthropic_propensity_dataset_human_written)\n",
    "display(anthropic_propensity_dataset_lm_written)\n",
    "\n",
    "anthropic_propensity_dataset_human_written.push_to_hub(\"Kyle1668/anthropic-propensity-evals\", \"human_generated_evals\")\n",
    "anthropic_propensity_dataset_lm_written.push_to_hub(\"Kyle1668/anthropic-propensity-evals\", \"lm_generated_evals\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
